{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9Ulq20EACFI"
      },
      "outputs": [],
      "source": [
        "!pip install numpy torch torchvision pandas tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLqO-0Z6E1Mr",
        "outputId": "6896fa8f-c78b-495d-ddb7-14c564ea4afe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100%|█████████████████████████████████████████| 125/125 [00:27<00:00,  4.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                    id                          label\n",
            "0     01pqvgnpo4kj20uc           009.Brewer_Blackbird\n",
            "1     01txr2cjmqt2mac3           124.Le_Conte_Sparrow\n",
            "2     01v6lr17lljyjrsb               035.Purple_Finch\n",
            "3     01yn4elsxm9vxfrj              078.Gray_Kingbird\n",
            "4     0390nt45sljdiv3o           168.Kentucky_Warbler\n",
            "...                ...                            ...\n",
            "1995  zx51lghpgb69x2kj             014.Indigo_Bunting\n",
            "1996  zxucbpfpy7e7egbl  041.Scissor_tailed_Flycatcher\n",
            "1997  zy44rh8ee6s0rlxp            018.Spotted_Catbird\n",
            "1998  zy97ewyvt1qjsd66               175.Pine_Warbler\n",
            "1999  zydmf1g651ft4kao           163.Cape_May_Warbler\n",
            "\n",
            "[2000 rows x 2 columns]\n",
            "Predictions saved to /content/drive/MyDrive/ML/predictions_cm2_abla.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.datasets.folder import default_loader\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import resnet101, densenet161\n",
        "from tqdm import tqdm\n",
        "from torchvision import transforms\n",
        "from os.path import join\n",
        "from torchvision.datasets.folder import ImageFolder\n",
        "from torchvision.models import efficientnet_b1\n",
        "\n",
        "\n",
        "net = efficientnet_b1(pretrained=False)\n",
        "in_features = net.classifier[1].in_features\n",
        "net.classifier[1] = nn.Linear(in_features, 200)\n",
        "\n",
        "# 這邊放入weight的那個檔案的路徑\n",
        "net.load_state_dict(torch.load(os.path.join('/content/drive/MyDrive/ML/max_acc_cm2.pth')))\n",
        "\n",
        "re_size = 512\n",
        "crop_size = 448\n",
        "batch_size = 16\n",
        "num_workers = 8\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.image_files = sorted(os.listdir(data_dir))\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.data_dir, self.image_files[idx])\n",
        "        image = default_loader(img_path)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return {\"image\": image, \"id\": os.path.splitext(self.image_files[idx])[0]}\n",
        "\n",
        "# 這邊放入要測試的data的資料夾路徑\n",
        "test_data_dir = '/content/drive/MyDrive/ML/data/test'\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((re_size, re_size)),\n",
        "    transforms.CenterCrop(crop_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "])\n",
        "\n",
        "\n",
        "test_dataset = CustomDataset(data_dir=test_data_dir, transform=test_transform)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "net.eval()\n",
        "\n",
        "predictions = []\n",
        "\n",
        "train_transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((re_size, re_size)),\n",
        "        transforms.RandomCrop(crop_size, padding=8),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "class_names = ['001.Black_footed_Albatross', '002.Laysan_Albatross', '003.Sooty_Albatross', '004.Groove_billed_Ani', '005.Crested_Auklet', '006.Least_Auklet', '007.Parakeet_Auklet', '008.Rhinoceros_Auklet', '009.Brewer_Blackbird', '010.Red_winged_Blackbird', '011.Rusty_Blackbird', '012.Yellow_headed_Blackbird', '013.Bobolink', '014.Indigo_Bunting', '015.Lazuli_Bunting', '016.Painted_Bunting', '017.Cardinal', '018.Spotted_Catbird', '019.Gray_Catbird', '020.Yellow_breasted_Chat', '021.Eastern_Towhee', '022.Chuck_will_Widow', '023.Brandt_Cormorant', '024.Red_faced_Cormorant', '025.Pelagic_Cormorant', '026.Bronzed_Cowbird', '027.Shiny_Cowbird', '028.Brown_Creeper', '029.American_Crow', '030.Fish_Crow', '031.Black_billed_Cuckoo', '032.Mangrove_Cuckoo', '033.Yellow_billed_Cuckoo', '034.Gray_crowned_Rosy_Finch', '035.Purple_Finch', '036.Northern_Flicker', '037.Acadian_Flycatcher', '038.Great_Crested_Flycatcher', '039.Least_Flycatcher', '040.Olive_sided_Flycatcher', '041.Scissor_tailed_Flycatcher', '042.Vermilion_Flycatcher', '043.Yellow_bellied_Flycatcher', '044.Frigatebird', '045.Northern_Fulmar', '046.Gadwall', '047.American_Goldfinch', '048.European_Goldfinch', '049.Boat_tailed_Grackle', '050.Eared_Grebe', '051.Horned_Grebe', '052.Pied_billed_Grebe', '053.Western_Grebe', '054.Blue_Grosbeak', '055.Evening_Grosbeak', '056.Pine_Grosbeak', '057.Rose_breasted_Grosbeak', '058.Pigeon_Guillemot', '059.California_Gull', '060.Glaucous_winged_Gull', '061.Heermann_Gull', '062.Herring_Gull', '063.Ivory_Gull', '064.Ring_billed_Gull', '065.Slaty_backed_Gull', '066.Western_Gull', '067.Anna_Hummingbird', '068.Ruby_throated_Hummingbird', '069.Rufous_Hummingbird', '070.Green_Violetear', '071.Long_tailed_Jaeger', '072.Pomarine_Jaeger', '073.Blue_Jay', '074.Florida_Jay', '075.Green_Jay', '076.Dark_eyed_Junco', '077.Tropical_Kingbird', '078.Gray_Kingbird', '079.Belted_Kingfisher', '080.Green_Kingfisher', '081.Pied_Kingfisher', '082.Ringed_Kingfisher', '083.White_breasted_Kingfisher', '084.Red_legged_Kittiwake', '085.Horned_Lark', '086.Pacific_Loon', '087.Mallard', '088.Western_Meadowlark', '089.Hooded_Merganser', '090.Red_breasted_Merganser', '091.Mockingbird', '092.Nighthawk', '093.Clark_Nutcracker', '094.White_breasted_Nuthatch', '095.Baltimore_Oriole', '096.Hooded_Oriole', '097.Orchard_Oriole', '098.Scott_Oriole', '099.Ovenbird', '100.Brown_Pelican', '101.White_Pelican', '102.Western_Wood_Pewee', '103.Sayornis', '104.American_Pipit', '105.Whip_poor_Will', '106.Horned_Puffin', '107.Common_Raven', '108.White_necked_Raven', '109.American_Redstart', '110.Geococcyx', '111.Loggerhead_Shrike', '112.Great_Grey_Shrike', '113.Baird_Sparrow', '114.Black_throated_Sparrow', '115.Brewer_Sparrow', '116.Chipping_Sparrow', '117.Clay_colored_Sparrow', '118.House_Sparrow', '119.Field_Sparrow', '120.Fox_Sparrow', '121.Grasshopper_Sparrow', '122.Harris_Sparrow', '123.Henslow_Sparrow', '124.Le_Conte_Sparrow', '125.Lincoln_Sparrow', '126.Nelson_Sharp_tailed_Sparrow', '127.Savannah_Sparrow', '128.Seaside_Sparrow', '129.Song_Sparrow', '130.Tree_Sparrow', '131.Vesper_Sparrow', '132.White_crowned_Sparrow', '133.White_throated_Sparrow', '134.Cape_Glossy_Starling', '135.Bank_Swallow', '136.Barn_Swallow', '137.Cliff_Swallow', '138.Tree_Swallow', '139.Scarlet_Tanager', '140.Summer_Tanager', '141.Artic_Tern', '142.Black_Tern', '143.Caspian_Tern', '144.Common_Tern', '145.Elegant_Tern', '146.Forsters_Tern', '147.Least_Tern', '148.Green_tailed_Towhee', '149.Brown_Thrasher', '150.Sage_Thrasher', '151.Black_capped_Vireo', '152.Blue_headed_Vireo', '153.Philadelphia_Vireo', '154.Red_eyed_Vireo', '155.Warbling_Vireo', '156.White_eyed_Vireo', '157.Yellow_throated_Vireo', '158.Bay_breasted_Warbler', '159.Black_and_white_Warbler', '160.Black_throated_Blue_Warbler', '161.Blue_winged_Warbler', '162.Canada_Warbler', '163.Cape_May_Warbler', '164.Cerulean_Warbler', '165.Chestnut_sided_Warbler', '166.Golden_winged_Warbler', '167.Hooded_Warbler', '168.Kentucky_Warbler', '169.Magnolia_Warbler', '170.Mourning_Warbler', '171.Myrtle_Warbler', '172.Nashville_Warbler', '173.Orange_crowned_Warbler', '174.Palm_Warbler', '175.Pine_Warbler', '176.Prairie_Warbler', '177.Prothonotary_Warbler', '178.Swainson_Warbler', '179.Tennessee_Warbler', '180.Wilson_Warbler', '181.Worm_eating_Warbler', '182.Yellow_Warbler', '183.Northern_Waterthrush', '184.Louisiana_Waterthrush', '185.Bohemian_Waxwing', '186.Cedar_Waxwing', '187.American_Three_toed_Woodpecker', '188.Pileated_Woodpecker', '189.Red_bellied_Woodpecker', '190.Red_cockaded_Woodpecker', '191.Red_headed_Woodpecker', '192.Downy_Woodpecker', '193.Bewick_Wren', '194.Cactus_Wren', '195.Carolina_Wren', '196.House_Wren', '197.Marsh_Wren', '198.Rock_Wren', '199.Winter_Wren', '200.Common_Yellowthroat']\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, ncols=80):\n",
        "        inputs = batch[\"image\"].cuda()\n",
        "        ids = batch[\"id\"]\n",
        "\n",
        "        net.cuda()\n",
        "\n",
        "        # predict\n",
        "        outputs = net(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        label_names = [f\"{label:03d}.{class_names[label]}\" for label in predicted]\n",
        "\n",
        "        # save the predict result\n",
        "        for img_id, label_id in zip(ids, label_names):\n",
        "            label_id = label_id.split('.', 1)[-1]\n",
        "            predictions.append({\"id\": img_id, \"label\": label_id})\n",
        "\n",
        "df = pd.DataFrame(predictions)\n",
        "\n",
        "print(df)\n",
        "\n",
        "# 這邊請放csv想要存的地方(是csv檔案的路徑，不是資料夾)\n",
        "csv_path = '/content/drive/MyDrive/ML/predictions_cm2.csv'\n",
        "df.to_csv(csv_path, index=False)\n",
        "print(f\"Predictions saved to {csv_path}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
